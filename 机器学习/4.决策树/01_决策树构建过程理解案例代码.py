# -- encoding:utf-8 --
"""
总样本：10条数据
  是：3个样本
  否：7个样本
特征1：房产
  4个有房产
    0个是 4个否
  6个没有房产
    3个是 3个否
特征2：婚姻情况
  4个单身
    2个是 2个否
  3个已婚
    0个是 3个否
  3个离婚
    1个是 2个否
特征3：年收入 60 75	 85	90	95	100	100	110	125	220
"""

import numpy as np


def entropy(t):
    """
    计算信息熵或者gini系数
    :param t: 各个的概率值
    :return:
    """
    # return 1.0 - np.sum([p * p for p in t])
    return np.sum([-pi * np.log2(pi) for pi in t])


print("选择第一个划分特征")
# a. 计算原始数据集中的信息熵
h = entropy([0.7, 0.3])
print("当前数据集中的目标属性的信息熵:%.3f" % h)
# b. 分别计算基于房产、基于婚姻情况、基于年收入的信息增益度 --> 计算条件熵
# i. 基于基于房产的信息增益度
# 第一个分支的概率以及对应数据的信息熵
p11 = 0.4
h11 = entropy([1.0])
# 第二个分支的概率以及对应数据的信息熵
p12 = 0.6
h12 = entropy([0.5, 0.5])
# 计算信息熵
h1 = p11 * h11 + p12 * h12
# 计算信息增益度
g1 = h - h1
print("以房产作为划分特征的条件熵:%.3f" % h1)
print("以房产作为划分特征的信息增益度:%.3f" % g1)

# ii. 基于基于婚姻情况的信息增益度
# 第一个分支的概率以及对应数据的信息熵 -> 单身 4、2、2
p21 = 0.4
h21 = entropy([0.5, 0.5])
# 第二个分支的概率以及对应数据的信息熵 -> 离婚 3、2、1
p22 = 0.3
h22 = entropy([1.0 / 3, 2.0 / 3])
# 第三个分支的概率以及对应数据的信息熵 -> 已婚 3、3、0
p23 = 0.3
h23 = entropy([1.0])
# 计算信息熵
h2 = p21 * h21 + p22 * h22 + p23 * h23
# 计算信息增益度
g2 = h - h2
print("以婚姻情况作为划分特征的条件熵:%.3f" % h2)
print("以婚姻情况作为划分特征的信息增益度:%.3f" % g2)

# iii. 基于年收入80的信息增益度
# 第一个分支的概率以及对应数据的信息熵 <= 80
p31 = 0.2
h31 = entropy([1.0])
# 第二个分支的概率以及对应数据的信息熵 > 80
p32 = 0.8
h32 = entropy([3.0 / 8, 5.0 / 8])
# 计算信息熵
h3 = p31 * h31 + p32 * h32
# 计算信息增益度
g3 = h - h3
print("以年收入80作为划分特征的条件熵:%.3f" % h3)
print("以年收入80作为划分特征的信息增益度:%.3f" % g3)

# iiii. 基于年收入97.5的信息增益度
# 第一个分支的概率以及对应数据的信息熵 <= 97.5
p41 = 0.5
h41 = entropy([2.0 / 5, 3.0 / 5])
# 第二个分支的概率以及对应数据的信息熵 > 97.5
p42 = 0.5
h42 = entropy([1.0])
# 计算信息熵
h4 = p41 * h41 + p42 * h42
# 计算信息增益度
g4 = h - h4
print("以年收入97.5作为划分特征的条件熵:%.3f" % h4)
print("以年收入97.5作为划分特征的信息增益度:%.3f" % g4)

print("\n" * 10)
print("选择第二个划分特征")
# a. 计算原始数据集中的信息熵
# 由于第一个特征选择了年收入97.5作为划分属性，所以子数据集中的信息熵分别为: h41和h42; 而且h42等于0，所以不需要继续处理，只需要对h41所对应的样本数据集做一个划分的操作
h = h41
print("当前数据集中的目标属性的信息熵:%.3f" % h)
# b. 分别计算基于房产、基于婚姻情况、基于年收入的信息增益度
# i. 基于基于房产的信息增益度
# 第一个分支的概率以及对应数据的信息熵 -> 是 1,1,0
p11 = 0.2
h11 = entropy([1.0])
# 第二个分支的概率以及对应数据的信息熵 -> 否 4,3,1
p12 = 0.8
h12 = entropy([3.0 / 4, 1.0 / 4])
# 计算信息熵
h1 = p11 * h11 + p12 * h12
# 计算信息增益度
g1 = h - h1
print("以房产作为划分特征的条件熵:%.3f" % h1)
print("以房产作为划分特征的信息增益度:%.3f" % g1)

# ii. 基于基于婚姻情况的信息增益度
# 第一个分支的概率以及对应数据的信息熵 -> 单身 2,2,0
p21 = 0.4
h21 = entropy([1.0])
# 第二个分支的概率以及对应数据的信息熵 -> 离婚 2,1,1
p22 = 0.4
h22 = entropy([0.5,0.5])
# 第三个分支的概率以及对应数据的信息熵 -> 已婚 1,0,1
p23 = 0.2
h23 = entropy([1.0])
# 计算信息熵
h2 = p21 * h21 + p22 * h22 + p23 * h23
# 计算信息增益度
g2 = h - h2
print("以婚姻情况作为划分特征的条件熵:%.3f" % h2)
print("以婚姻情况作为划分特征的信息增益度:%.3f" % g2)

# iii. 基于年收入80的信息增益度
# 第一个分支的概率以及对应数据的信息熵 <= 80
p31 = 0.4
h31 = entropy([1.0])
# 第二个分支的概率以及对应数据的信息熵 > 80
p32 = 0.6
h32 = entropy([1.0])
# 计算信息熵
h3 = p31 * h31 + p32 * h32
# 计算信息增益度
g3 = h - h3
print("以年收入80作为划分特征的条件熵:%.3f" % h3)
print("以年收入80作为划分特征的信息增益度:%.3f" % g3)

